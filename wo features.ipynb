{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbdea956",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test_fg\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "path = r\"G:\\Signature Verification Project\\data\\sign_data\\test\"\n",
    "unique_id = [] ## name or id of each image (same as the id in train_data.csv)\n",
    "images = [] ## image array\n",
    "\n",
    "for folder, a, b in os.walk(path):\n",
    "    for file in b:\n",
    "        img = cv2.imread(os.path.join(folder, file)) ## reading image as matrix\n",
    "        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            \n",
    "            ## creating  unique id for each image\n",
    "            if \"forg\" in str(folder):\n",
    "                unique_id.append(str(folder[-8:]) + \"/\" + str(file.lower()))\n",
    "            else:\n",
    "                unique_id.append(str(folder[-3:]) + \"/\" + str(file.lower()))\n",
    "                \n",
    "## grayscaling and resizing the images\n",
    "\n",
    "resized_images = []\n",
    "dimension = (120, 80) ## new size (width, height)\n",
    "\n",
    "for img in images:\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ## grayscaling\n",
    "    \n",
    "    resized_image = cv2.resize(img, dimension, interpolation = cv2.INTER_AREA) ## resizing\n",
    "    \n",
    "    resized_images.append(resized_image)\n",
    "    \n",
    "    \n",
    "## creating dataframe from above info\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test_fg = pd.DataFrame(list(zip(unique_id, resized_images)), columns = [\"ID_fg\", \"images_fg\"])\n",
    "\n",
    "del unique_id, images, resized_images, path, dimension, resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31d5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test_g\n",
    "\n",
    "path = r\"G:\\Signature Verification Project\\data\\Again\\sign_data\\test\\genuine\"\n",
    "unique_id = [] ## name or id of each image (same as the id in train_data.csv)\n",
    "images = [] ## image array\n",
    "\n",
    "for folder, a, b in os.walk(path):\n",
    "    for file in b:\n",
    "        img = cv2.imread(os.path.join(folder, file)) ## reading image as matrix\n",
    "        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            \n",
    "            ## creating  unique id for each image\n",
    "            if \"forg\" in str(folder):\n",
    "                unique_id.append(str(folder[-8:]) + \"/\" + str(file.lower()))\n",
    "            else:\n",
    "                unique_id.append(str(folder[-3:]) + \"/\" + str(file.lower()))\n",
    "                \n",
    "## grayscaling and resizing the images\n",
    "\n",
    "resized_images = []\n",
    "dimension = (120, 80) ## new size (width, height)\n",
    "\n",
    "for img in images:\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ## grayscaling\n",
    "    \n",
    "    resized_image = cv2.resize(img, dimension, interpolation = cv2.INTER_AREA) ## resizing\n",
    "    \n",
    "    resized_images.append(resized_image)\n",
    "    \n",
    "    \n",
    "## creating dataframe from above info\n",
    "\n",
    "test_g = pd.DataFrame(list(zip(unique_id, resized_images)), columns = [\"ID_g\", \"images_g\"])\n",
    "\n",
    "del unique_id, images, resized_images, path, dimension, resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f200c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_fg\n",
    "\n",
    "path = r\"G:\\Signature Verification Project\\data\\sign_data\\train\"\n",
    "unique_id = [] ## name or id of each image (same as the id in train_data.csv)\n",
    "images = [] ## image array\n",
    "\n",
    "for folder, a, b in os.walk(path):\n",
    "    for file in b:\n",
    "        img = cv2.imread(os.path.join(folder, file)) ## reading image as matrix\n",
    "        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            \n",
    "            ## creating  unique id for each image\n",
    "            if \"forg\" in str(folder):\n",
    "                unique_id.append(str(folder[-8:]) + \"/\" + str(file.lower()))\n",
    "            else:\n",
    "                unique_id.append(str(folder[-3:]) + \"/\" + str(file.lower()))\n",
    "                \n",
    "## grayscaling and resizing the images\n",
    "\n",
    "resized_images = []\n",
    "dimension = (120, 80) ## new size (width, height)\n",
    "\n",
    "for img in images:\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ## grayscaling\n",
    "    \n",
    "    resized_image = cv2.resize(img, dimension, interpolation = cv2.INTER_AREA) ## resizing\n",
    "    \n",
    "    resized_images.append(resized_image)\n",
    "    \n",
    "    \n",
    "## creating dataframe from above info\n",
    "\n",
    "train_fg = pd.DataFrame(list(zip(unique_id, resized_images)), columns = [\"ID_fg\", \"images_fg\"])\n",
    "\n",
    "del unique_id, images, resized_images, path, dimension, resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4f8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_g\n",
    "\n",
    "path = r\"G:\\Signature Verification Project\\data\\Again\\sign_data\\train\\Genuine\"\n",
    "unique_id = [] ## name or id of each image (same as the id in train_data.csv)\n",
    "images = [] ## image array\n",
    "\n",
    "for folder, a, b in os.walk(path):\n",
    "    for file in b:\n",
    "        img = cv2.imread(os.path.join(folder, file)) ## reading image as matrix\n",
    "        \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            \n",
    "            ## creating  unique id for each image\n",
    "            if \"forg\" in str(folder):\n",
    "                unique_id.append(str(folder[-8:]) + \"/\" + str(file.lower()))\n",
    "            else:\n",
    "                unique_id.append(str(folder[-3:]) + \"/\" + str(file.lower()))\n",
    "                \n",
    "## grayscaling and resizing the images\n",
    "\n",
    "resized_images = []\n",
    "dimension = (120, 80) ## new size (width, height)\n",
    "\n",
    "for img in images:\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ## grayscaling\n",
    "    \n",
    "    resized_image = cv2.resize(img, dimension, interpolation = cv2.INTER_AREA) ## resizing\n",
    "    \n",
    "    resized_images.append(resized_image)\n",
    "    \n",
    "    \n",
    "## creating dataframe from above info\n",
    "\n",
    "train_g = pd.DataFrame(list(zip(unique_id, resized_images)), columns = [\"ID_g\", \"images_g\"])\n",
    "\n",
    "del unique_id, images, resized_images, path, dimension, resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d422e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## final test\n",
    "\n",
    "test_g['key'] = test_g['ID_g'].str[:3]\n",
    "test_fg['key'] = test_fg['ID_fg'].str[:3]\n",
    "\n",
    "test_result = pd.merge(test_g, test_fg, on ='key').drop(\"key\", 1)\n",
    "\n",
    "test_y = pd.read_csv(r\"G:\\Signature Verification Project\\data\\sign_data\\test_data.csv\")\n",
    "\n",
    "test_result[\"new_key\"] = test_result[[\"ID_g\", \"ID_fg\"]].apply(lambda x: \"_\".join(x), axis = 1)\n",
    "test_y[\"new_key\"] = test_y[[\"ID\", \"opposite_image\"]].apply(lambda x: \"_\".join(x), axis = 1)\n",
    "\n",
    "final_test = test_result.merge(test_y, how = \"left\", left_on = \"new_key\", right_on = \"new_key\")\n",
    "\n",
    "final_test = final_test.drop([\"new_key\", \"ID\", \"opposite_image\"], axis = 1)\n",
    "\n",
    "del test_g, test_fg, test_result, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96405274",
   "metadata": {},
   "outputs": [],
   "source": [
    "## final train\n",
    "\n",
    "train_g['key'] = train_g['ID_g'].str[:3]\n",
    "train_fg['key'] = train_fg['ID_fg'].str[:3]\n",
    "\n",
    "train_result = pd.merge(train_g, train_fg, on ='key').drop(\"key\", 1)\n",
    "\n",
    "train_y = pd.read_csv(r\"G:\\Signature Verification Project\\data\\sign_data\\train_data.csv\")\n",
    "\n",
    "train_result[\"new_key\"] = train_result[[\"ID_g\", \"ID_fg\"]].apply(lambda x: \"_\".join(x), axis = 1)\n",
    "train_y[\"new_key\"] = train_y[[\"ID\", \"opposite_image\"]].apply(lambda x: \"_\".join(x), axis = 1)\n",
    "\n",
    "final_train = train_result.merge(train_y, how = \"left\", left_on = \"new_key\", right_on = \"new_key\")\n",
    "\n",
    "final_train = final_train.drop([\"new_key\", \"ID\", \"opposite_image\"], axis = 1)\n",
    "\n",
    "del train_g, train_fg, train_result, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96afabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c944cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The last dimension of the inputs to `Dense` should be defined. Found `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e5939e1b9610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    876\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2623\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2624\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2625\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2626\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2627\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m       raise ValueError('The last dimension of the inputs to `Dense` '\n\u001b[0m\u001b[0;32m   1189\u001b[0m                        'should be defined. Found `None`.')\n\u001b[0;32m   1190\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The last dimension of the inputs to `Dense` should be defined. Found `None`."
     ]
    }
   ],
   "source": [
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Flatten()(inception.output)\n",
    "\n",
    "prediction = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inception.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a28814",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=[tensorflow.keras.metrics.AUC(),\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd0dcf",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(\n",
    "  final_train,\n",
    "  validation_data=final_test,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=len(final_train),\n",
    "  validation_steps=len(final_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history['loss'], label='Training Loss')\n",
    "plt.plot(result.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Loss_Value')\n",
    "\n",
    "\n",
    "plt.plot(result.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(result.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Accuracy_Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
